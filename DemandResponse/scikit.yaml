apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: ml-pipeline-4 # executable ID, must be unique across your SAP AI Core instance, for example use `server-pipeline-yourname-1234`
  annotations:
    scenarios.ai.sap.com/description: "Learning to predict demand response"
    scenarios.ai.sap.com/name: "Demand Response (Tutorial)"
    executables.ai.sap.com/description: "Create online server to make live predictions"
    executables.ai.sap.com/name: "server"# Suggest the kind of artifact to input.
  labels:
    scenarios.ai.sap.com/id: "demandresponse-code"
    ai.sap.com/version: "3.0"
spec:
  inputs:
    parameters:
      - name: greetmessage # placeholder name
        type: string # placeholder name, do not add `-` in value use only alphanumeric chars
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      labels: |
        ai.sap.com/resourcePlan: starter # computing power
    spec: |
      predictor:
        imagePullSecrets:
          - name: vbrepo   # your docker registry secret
        containers:
        - name: kserve-container
          image: docker.io/vikrambhat2/vb_ml_model:latest
          ports:
            - containerPort: 3000    # customizable port
              protocol: TCP
          command: ["/bin/sh", "-c"]
          args:
            - >
              set -e && echo "Starting" && gunicorn --chdir /app/src main:app -b 0.0.0.0:3000
          env:
            - name: greetingmessage # different name to avoid confusion
              value: "{{inputs.parameters.greetmessage}}"


